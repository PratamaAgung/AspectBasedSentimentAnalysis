{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formalizer(string):\n",
    "    req = requests.post(\"http://127.0.0.1:9000/formalizer\", json= {\"string\": string})\n",
    "    response = req.json()\n",
    "    if response['status'] == 'success':\n",
    "        return response['data']\n",
    "    else:\n",
    "        print(response)\n",
    "        return None\n",
    "    \n",
    "def stemmer(string):\n",
    "    req = requests.post(\"http://127.0.0.1:9000/stemmer\", json= {\"string\": string})\n",
    "    response = req.json()\n",
    "    if response['status'] == 'success':\n",
    "        return response['data']\n",
    "    else:\n",
    "        print(response)\n",
    "        return None\n",
    "    \n",
    "def tokenizer(string):\n",
    "    req = requests.post(\"http://127.0.0.1:9000/sentence/tokenizer\", json= {\"string\": string})\n",
    "    response = req.json()\n",
    "    if response['status'] == 'success':\n",
    "        return response['data']\n",
    "    else:\n",
    "        print(response)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('label/review1.csv')\n",
    "data2 = pd.read_csv('label/review5.csv')\n",
    "data3 = pd.read_csv('label/review1_2.csv')\n",
    "data4 = pd.read_csv('label/review2_2.csv')\n",
    "data5 = pd.read_csv('label/review3_2.csv')\n",
    "data6 = pd.read_csv('label/review5_2.csv')\n",
    "\n",
    "datal = [data1, data2, data3, data4, data5, data6]\n",
    "data = pd.concat(datal)\n",
    "data = data[['review', 'produk', 'packaging', 'pengiriman', 'general']].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aspect = []\n",
    "for d in data:\n",
    "    d_aspect = [d[0]] + [1 if aspect != 0 else 0 for aspect in d[1:]]\n",
    "    data_aspect.append(d_aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = []\n",
    "for d in data:\n",
    "    formalized_data = formalizer(d[0])\n",
    "    stemmed_data = stemmer(formalized_data)\n",
    "    preprocessed_data.append(stemmed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [d[1:] for d in data_aspect]\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(preprocessed_data, y, test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for produk\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.67      0.70        21\n",
      "           1       0.84      0.88      0.86        43\n",
      "\n",
      "   micro avg       0.81      0.81      0.81        64\n",
      "   macro avg       0.79      0.78      0.78        64\n",
      "weighted avg       0.81      0.81      0.81        64\n",
      "\n",
      "Classification report for packaging\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        46\n",
      "           1       0.78      0.78      0.78        18\n",
      "\n",
      "   micro avg       0.88      0.88      0.88        64\n",
      "   macro avg       0.85      0.85      0.85        64\n",
      "weighted avg       0.88      0.88      0.88        64\n",
      "\n",
      "Classification report for pengiriman\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84        37\n",
      "           1       0.80      0.74      0.77        27\n",
      "\n",
      "   micro avg       0.81      0.81      0.81        64\n",
      "   macro avg       0.81      0.80      0.81        64\n",
      "weighted avg       0.81      0.81      0.81        64\n",
      "\n",
      "Classification report for general\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97        61\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.94      0.94      0.94        64\n",
      "   macro avg       0.48      0.49      0.48        64\n",
      "weighted avg       0.91      0.94      0.92        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "                ('vectorize', CountVectorizer(ngram_range= (1,2))),\n",
    "                ('clf', LinearSVC())\n",
    "            ])\n",
    "\n",
    "for i, categories in enumerate(['produk', 'packaging', 'pengiriman', 'general']):\n",
    "    pipeline.fit(train_x, [t[i] for t in train_y])\n",
    "    prediction = pipeline.predict(test_x)\n",
    "    print(\"Classification report for {}\".format(categories))\n",
    "    report = classification_report([t[i] for t in test_y], prediction)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df= 1)\n",
    "X = vectorizer.fit_transform(preprocessed_data).toarray()\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "\n",
    "tokenized = [list(map(lambda x: vectorizer.vocabulary_.get(x), analyzer(line))) for line in preprocessed_data]\n",
    "\n",
    "y = [d[1:] for d in data_aspect]\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(tokenized, y, test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_words = 40\n",
    "train_x = sequence.pad_sequences(train_x, maxlen= max_words)\n",
    "test_x = sequence.pad_sequences(test_x, maxlen= max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 5ms/step\n",
      "Accuracy report for produk: 0.78125\n",
      "64/64 [==============================] - 0s 562us/step\n",
      "Accuracy report for packaging: 0.6875\n",
      "64/64 [==============================] - 0s 497us/step\n",
      "Accuracy report for pengiriman: 0.453125\n",
      "64/64 [==============================] - 0s 567us/step\n",
      "Accuracy report for general: 0.984375\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "embedding_size = 64\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vectorizer.vocabulary_), embedding_size, input_length= max_words))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation= 'sigmoid'))\n",
    "\n",
    "model.compile(loss= 'binary_crossentropy', optimizer= 'adam', metrics= ['accuracy'])\n",
    "\n",
    "for i, categories in enumerate(['produk', 'packaging', 'pengiriman', 'general']):\n",
    "    model.fit(train_x, [t[i] for t in train_y], epochs= 16, verbose= 0)\n",
    "    scores = model.evaluate(test_x, [t[i] for t in test_y])\n",
    "    print(\"Accuracy report for {}: {}\".format(categories, scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polarization aspect for 'produk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = []\n",
    "data_y = []\n",
    "i = 1\n",
    "for d, s in zip(preprocessed_data, data):\n",
    "    if (s[i] != 0):\n",
    "        data_x.append(d)\n",
    "        data_y.append(1 if s[i] == 1 else 0)\n",
    "        \n",
    "train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for general\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80        15\n",
      "           1       0.84      1.00      0.92        27\n",
      "\n",
      "   micro avg       0.88      0.88      0.88        42\n",
      "   macro avg       0.92      0.83      0.86        42\n",
      "weighted avg       0.90      0.88      0.87        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "                ('vectorize', TfidfVectorizer(ngram_range= (1,2))),\n",
    "                ('clf', LinearSVC())\n",
    "            ])\n",
    "\n",
    "pipeline.fit(train_x, train_y)\n",
    "prediction = pipeline.predict(test_x)\n",
    "print(\"Classification report for {}\".format(categories))\n",
    "report = classification_report(test_y, prediction)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polarization aspect for 'packaging'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = []\n",
    "data_y = []\n",
    "i = 2\n",
    "for d, s in zip(preprocessed_data, data):\n",
    "    if (s[i] != 0):\n",
    "        data_x.append(d)\n",
    "        data_y.append(1 if s[i] == 1 else 0)\n",
    "        \n",
    "train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for general\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80         8\n",
      "           1       0.86      0.92      0.89        13\n",
      "\n",
      "   micro avg       0.86      0.86      0.86        21\n",
      "   macro avg       0.86      0.84      0.84        21\n",
      "weighted avg       0.86      0.86      0.86        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "                ('vectorize', TfidfVectorizer(ngram_range= (1,2))),\n",
    "                ('clf', LinearSVC())\n",
    "            ])\n",
    "\n",
    "pipeline.fit(train_x, train_y)\n",
    "prediction = pipeline.predict(test_x)\n",
    "print(\"Classification report for {}\".format(categories))\n",
    "report = classification_report(test_y, prediction)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polarization aspect for 'pengiriman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = []\n",
    "data_y = []\n",
    "i = 3\n",
    "for d, s in zip(preprocessed_data, data):\n",
    "    if (s[i] != 0):\n",
    "        data_x.append(d)\n",
    "        data_y.append(1 if s[i] == 1 else 0)\n",
    "        \n",
    "train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for general\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        13\n",
      "           1       0.88      1.00      0.94        15\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        28\n",
      "   macro avg       0.94      0.92      0.93        28\n",
      "weighted avg       0.94      0.93      0.93        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "                ('vectorize', TfidfVectorizer(ngram_range= (1,2))),\n",
    "                ('clf', LinearSVC())\n",
    "            ])\n",
    "\n",
    "pipeline.fit(train_x, train_y)\n",
    "prediction = pipeline.predict(test_x)\n",
    "print(\"Classification report for {}\".format(categories))\n",
    "report = classification_report(test_y, prediction)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
